ğŸ›¡ï¸ Credit Card Fraud Detection
ğŸ“Œ About the Dataset

Sumber: Kaggle - Credit Card Fraud Detection

Transaksi kartu kredit di Eropa, September 2013.

Periode 2 hari, total 284,807 transaksi dengan 492 kasus fraud.

Highly imbalanced â†’ hanya 0.172% data yang fraud.

Fitur:

V1 â€¦ V28 â†’ hasil transformasi PCA.

Time â†’ detik sejak transaksi pertama.

Amount â†’ jumlah transaksi.

Class â†’ label target (1 = fraud, 0 = normal).

âš ï¸ Karena imbalance, metrik AUPRC (Area Under Precision-Recall Curve) lebih bermakna dibanding akurasi biasa.

ğŸ“ Formula AUPRC
AUPRC
=
âˆ«
0
1
ğ‘ƒ
ğ‘Ÿ
ğ‘’
ğ‘
ğ‘–
ğ‘ 
ğ‘–
ğ‘œ
ğ‘›
(
ğ‘…
ğ‘’
ğ‘
ğ‘
ğ‘™
ğ‘™
)
â€‰
ğ‘‘
ğ‘…
ğ‘’
ğ‘
ğ‘
ğ‘™
ğ‘™
AUPRC=âˆ«
0
1
	â€‹

Precision(Recall)dRecall

atau secara diskret (approx):

AUPRC
=
âˆ‘
ğ‘–
=
1
ğ‘›
âˆ’
1
(
ğ‘…
ğ‘’
ğ‘
ğ‘
ğ‘™
ğ‘™
ğ‘–
+
1
âˆ’
ğ‘…
ğ‘’
ğ‘
ğ‘
ğ‘™
ğ‘™
ğ‘–
)
â‹…
ğ‘ƒ
ğ‘Ÿ
ğ‘’
ğ‘
ğ‘–
ğ‘ 
ğ‘–
ğ‘œ
ğ‘›
ğ‘–
+
1
AUPRC=
i=1
âˆ‘
nâˆ’1
	â€‹

(Recall
i+1
	â€‹

âˆ’Recall
i
	â€‹

)â‹…Precision
i+1
	â€‹

ğŸš€ Modeling Approach

Saya menggunakan ensemble gradient boosting models yang populer untuk imbalance classification:

XGBoost â†’ tree-based boosting, menggunakan parameter scale_pos_weight untuk imbalance.

CatBoost â†’ boosting dengan class_weights, lebih robust dan easy-to-tune.

ğŸ“Š Performance (Test Data)
Model	AUPRC	Catatan
XGBoost	0.894	Terbaik, recall tinggi, balance precision.
CatBoost	0.888	Hampir setara, lebih stabil.
ğŸ§ª Full Dataset Prediction (XGBoost GAN-trained model)

Evaluasi prediksi di seluruh dataset asli:

Total samples : 283,718

Correct preds : 283,698

Incorrect preds : 20

Accuracy : 0.9999

ğŸ“Œ Confusion Matrix Breakdown

True Negatives (TN): 283,239 â†’ transaksi normal terdeteksi benar.

False Positives (FP): 6 â†’ transaksi normal salah ditandai fraud.

False Negatives (FN): 14 â†’ fraud lolos (kerugian potensial).

True Positives (TP): 459 â†’ fraud berhasil ditangkap.

ğŸ† Insight & Business Impact

Dengan AUPRC hampir 0.90, model mampu menangkap mayoritas fraud meski dataset sangat imbalance.

Dari 492 fraud asli, model berhasil mendeteksi 459 kasus â†’ recall ~93%.

False positives hanya 6 kasus â†’ artinya hanya sedikit customer terganggu.

False negatives 14 kasus â†’ ini adalah fokus perbaikan, karena setiap fraud yang lolos = potensi kerugian finansial.

ğŸ¯ Kesimpulan

XGBoost outperform CatBoost tipis pada AUPRC (0.894 vs 0.888).

Akurasi tinggi tidak berarti di kasus imbalance, tapi breakdown confusion matrix menunjukkan model sangat efektif.

Bisa dipakai sebagai fraud detection engine real-time untuk memblokir transaksi mencurigakan.
